#!/bin/bash
# bashreduce: mapreduce in bash
# erik@fawx.com

usage() {
	echo "Usage: $1 --hosts|-h '<host>[ <host>][...]' " \
		"[--column|-c <column>]" >&2
	echo "       [--map|-m <map>] [--reduce|-r <reduce>] [--mirror]" >&2
	echo "       [--input|-i <input>] [--output <output>]" >&2
	echo "       [--tmp <tmp>] [-S <sort-mem-MB>] [--help]" >&2
	if [ -n "$2" ] ; then
		echo "  --hosts  hosts to use; can repeat hosts for multiple cores" >&2
		echo "           (defaults to contents of /etc/br.hosts)" >&2
		echo "  --column column to use during partitioning (defaults to 1)" >&2
		echo "  --map    map program (effectively defaults to cat)" >&2
		echo "  --reduce reduce program" >&2
		echo "  --mirror assume the input data is mirrored on each node" >&2
		echo "  --input  input directory; to use a file, redirect stdin" >&2
		echo "           (defaults to stdin)" >&2
		echo "  --output output directory; to use a file, redirect stdout" >&2
		echo "           (defaults to stdin)" >&2
		echo "  --tmp    tmp directory (defaults to /tmp)" >&2
		echo "  -S       memory to use for sort (defaults to 256M)" >&2
		echo "  --help   this help message" >&2
	fi
	exit 2
}

# Defaults
hosts=
column=1
map=
reduce=
mirror=false
input=
output=
tmp=/tmp
sort_mem=256M

# TODO: Allow --thing=stuff syntax, too
program=$(basename $0)
set -- $(getopt --unquoted --name $program --options "h:c:m:r:Mi:o:t:S:" \
	--longoptions \
	"hosts:,column:,map:,reduce:,mirror,input:,output:,tmp:,help" \
	-- "$@") \
	|| usage $program
[[ $# -eq 0 ]] && usage $program
last=
while [[ $# -gt 0 ]] ; do
	case "$1" in
		-h|--hosts) last=h; hosts=$2; shift 2;;
		-c|--column) last=c; column=$2; shift 2;;
		-m|--map) last=m; map=$2; shift 2;;
		-r|--reduce) last=r; reduce=$2; shift 2;;
		-M|--mirror) last=M; mirror=true; shift;;
		-i|--input) last=i; input=$2; shift 2;;
		-o|--output) last=o; output=$2; shift 2;;
		-t|--tmp) last=t; tmp=$2; shift 2;;
		-S) last=S; sort_mem=$2; shift 2;;
		--help) usage $program MOAR;;
		--) unset last; shift;;
		*) if [[ "$last" == h ]]; then hosts="$hosts $1"; shift;
			else usage $program; fi;;
	esac
done 
unset last

# If --hosts wasn't given, try /etc/br.hosts
if [[ -z "$hosts" ]]; then
	if [[ -e /etc/br.hosts ]]; then
		hosts=$(cat /etc/br.hosts)
	else
		echo "$program: must specify --hosts or provide /etc/br.hosts"
		usage $program
	fi
fi

# Setup map and reduce as parts of a pipeline
[[ -n "$map" ]] && map="| $map 2>>/tmp/br_stderr"
[[ $mirror == true ]] && map="| xargs --verbose cat $map 2>>/tmp/br_stderr"
[[ -n "$reduce" ]] && reduce="| $reduce 2>>/tmp/br_stderr"

jobid="$(uuidgen)"
jobpath="$tmp/br_job_$jobid"
nodepath="$tmp/br_node_$jobid"
mkdir -p $jobpath/{in,out}

port_in=8192
port_out=$(($port_in + 1))
host_idx=0
out_files=
for host in $hosts; do
	mkfifo $jobpath/{in,out}/$host_idx

	# Listen for work (remote)
	ssh -n $host "mkdir -p $nodepath/"
	pid=$(ssh -n $host "nc -l -p $port_out >$nodepath/$host_idx \
		2>>/tmp/br_stderr </dev/null & jobs -l" \
		| awk {'print $2'})

	# Do work (remote)
	ssh -n $host "tail -s0.1 -f --pid=$pid $nodepath/$host_idx \
		2>>/tmp/br_stderr </dev/null \
		| LC_ALL='$LC_ALL' sort -S$sort_mem -T$tmp -k$column,$column \
		2>>/tmp/br_stderr \
		$map $reduce \
		| nc -q0 -l -p $port_in >>/tmp/br_stderr &"

	# Send work (local)
	nc $host $port_in >$jobpath/in/$host_idx &

	# Receive results (local)
	nc -q0 $host $port_out <$jobpath/out/$host_idx &
	out_files="$out_files $jobpath/out/$host_idx"

	# ++i
	port_in=$(($port_in + 2))
	port_out=$(($port_in + 1))
	host_idx=$(($host_idx + 1))

done

# Partition local input to the remote workers
if which brp >>/tmp/br_stderr; then
	BRP=brp
elif [[ -f brutils/brp ]]; then
	BRP=brutils/brp
fi
if [[ -n "$BRP" ]]; then
	eval "${input:+pv $input |} $BRP - $(($column - 1)) $out_files"
else
	# use awk if we don't have brp
	# we're taking advantage of a special property that awk leaves its file handles open until its done
	# i think this is universal
	# we're also sending a zero length string to all the handles at the end, in case some pipe got no love
	eval "${input:+pv $input |} awk '{
			srand(\$$column);
			print \$0 >>\"$jobpath/out/\"int(rand() * $host_idx);
		}
		END {
			for (i = 0; i != $host_idx; ++i)
				printf \"\" >>\"$jobpath/out/\"i;
		}'"
fi

# TODO: Merge output from hosts into one (maybe but not necessarily just
# a re-reduce)
if which brm >>/tmp/br_stderr; then
	BRM=brm
elif [[ -f brutils/brm ]]; then
	BRP=brutils/brm
fi
if [[ -n "$BRM" ]]; then
	eval "$BRM- $(($column - 1)) `find $jobpath/in/ -type p | xargs` ${output:+| pv >$output}"
else
	# use sort -m if we don't have brm
	# sort -m creates tmp files if too many input files are specified
	# brm doesn't do this
	eval "sort -k$column,$column -m $jobpath/in/* ${output:+| pv >$output}"
fi

# Cleanup
rm -rf $jobpath
for host in $hosts; do
	ssh $host "rm -rf $nodepath"
done

# TODO: is there a safe way to kill subprocesses upon fail?
# this seems to work: /bin/kill -- -$$
