#!/bin/bash
# bashreduce: mapreduce in bash
# erik@fawx.com

usage() {
	echo "Usage: $1 [-h|--hosts '<host>[ <host>][...]']" \
		"[-f|--filenames]" >&2
	echo "       [-m|--map <map>] [-r|--reduce <reduce>]" >&2
	echo "       [-i|--input <input>] [-o|--output <output>]" >&2
	echo "       [-c|--column <column>] [-S <sort-mem-MB>]" >&2
	echo "       [-t|--tmp <tmp>] [--help]" >&2
	if [ -n "$2" ] ; then
		echo "  --hosts     hosts to use; repeat hosts for multiple cores" >&2
		echo "              (defaults to contents of /etc/br.hosts)" >&2
		echo "  --filenames send filenames, not data, over the network," >&2
		echo "              implies each host has a mirror of the dataset" >&2
		echo "  --map       map program (effectively defaults to cat)" >&2
		echo "  --reduce    reduce program" >&2
		echo "  --mirror    assume the input data is mirrored on each node" >&2
		echo "  --input     input file or directory (defaults to stdin)" >&2
		echo "  --output    output file (defaults to stdout)" >&2
		echo "  --column    column used by sort (defaults to 1)" >&2
		echo "  -S          memory to use for sort (defaults to 256M)" >&2
		echo "  --tmp       tmp directory (defaults to /tmp)" >&2
		echo "  --help      this help message" >&2
	fi
	exit 2
}

# Defaults
hosts=
filenames=false
map=
reduce=
input=
output=
column=1
sort_mem=256M
tmp=/tmp

# TODO: Allow -tstuff and --thing=stuff syntax, too
program=$(basename $0)
set -- $(getopt --unquoted --name $program --options "h:fm:r:i:o:c:S:t:" \
	--longoptions \
	"hosts:,filenames,map:,reduce:,input:,output:,column:,tmp:,help" \
	-- "$@") \
	|| usage $program
[[ $# -eq 0 ]] && usage $program
last=
while [[ $# -gt 0 ]] ; do
	case "$1" in
		-h|--hosts) last=h; hosts=$2; shift 2;;
		-f|--filenames) last=f; filenames=true; shift;;
		-m|--map) last=m; map=$2; shift 2;;
		-r|--reduce) last=r; reduce=$2; shift 2;;
		-i|--input) last=i; input=$2; shift 2;;
		-o|--output) last=o; output=$2; shift 2;;
		-c|--column) last=c; column=$2; shift 2;;
		-S) last=S; sort_mem=$2; shift 2;;
		-t|--tmp) last=t; tmp=$2; shift 2;;
		--help) usage $program MOAR;;
		--) unset last; shift;;
		*) if [[ "$last" == h ]]; then hosts="$hosts $1"; shift;
			else usage $program; fi;;
	esac
done 
unset last

# If --hosts wasn't given, try /etc/br.hosts
if [[ -z "$hosts" ]]; then
	if [[ -e /etc/br.hosts ]]; then
		hosts=$(cat /etc/br.hosts)
	else
		echo "$program: must specify --hosts or provide /etc/br.hosts"
		usage $program
	fi
fi

# Start br_stderr from a clean slate
cp /dev/null $tmp/br_stderr

# Setup map and reduce as parts of a pipeline
[[ -n "$map" ]] && map="| $map 2>>$tmp/br_stderr"
[[ $filenames == true ]] && map="| xargs --verbose cat $map 2>>$tmp/br_stderr"
[[ -n "$reduce" ]] && reduce="| $reduce 2>>$tmp/br_stderr"

jobid="$(uuidgen)"
jobpath="$tmp/br_job_$jobid"
nodepath="$tmp/br_node_$jobid"
mkdir -p $jobpath/{in,out}

port_in=8192
port_out=$(($port_in + 1))
host_idx=0
out_files=
for host in $hosts; do
	mkfifo $jobpath/{in,out}/$host_idx

	# Listen for work (remote)
	ssh -n $host "mkdir -p $nodepath/"
	pid=$(ssh -n $host "nc -l -p $port_out >$nodepath/$host_idx \
		2>>$tmp/br_stderr </dev/null & jobs -l" \
		| awk {'print $2'})

	# Do work (remote)
	ssh -n $host "tail -s0.1 -f --pid=$pid $nodepath/$host_idx \
		2>>$tmp/br_stderr </dev/null \
		| LC_ALL='$LC_ALL' sort -S$sort_mem -T$tmp -k$column,$column \
		2>>$tmp/br_stderr \
		$map $reduce \
		| nc -q0 -l -p $port_in >>$tmp/br_stderr &"

	# Send work (local)
	nc $host $port_in >$jobpath/in/$host_idx &

	# Receive results (local)
	nc -q0 $host $port_out <$jobpath/out/$host_idx &
	out_files="$out_files $jobpath/out/$host_idx"

	# ++i
	port_in=$(($port_in + 2))
	port_out=$(($port_in + 1))
	host_idx=$(($host_idx + 1))

done

# Create the command to produce input
if [[ -d "$input" ]]; then
	input="find $input -type f |"
elif [[ -f "$input" ]]; then
	input="pv $input |"
else
	input=
fi

# Partition local input to the remote workers
if which brp >>$tmp/br_stderr; then
	BRP=brp
elif [[ -f brutils/brp ]]; then
	BRP=brutils/brp
fi
if [[ -n "$BRP" ]]; then
	eval "$input $BRP - $(($column - 1)) $out_files"
else
	# use awk if we don't have brp
	# we're taking advantage of a special property that awk leaves its file handles open until its done
	# i think this is universal
	# we're also sending a zero length string to all the handles at the end, in case some pipe got no love
	eval "$input awk '{
			srand(\$$column);
			print \$0 >>\"$jobpath/out/\"int(rand() * $host_idx);
		}
		END {
			for (i = 0; i != $host_idx; ++i)
				printf \"\" >>\"$jobpath/out/\"i;
		}'"
fi

# TODO: Merge output from hosts into one (maybe but not necessarily just
# a re-reduce)
if which brm >>$tmp/br_stderr; then
	BRM=brm
elif [[ -f brutils/brm ]]; then
	BRP=brutils/brm
fi
if [[ -n "$BRM" ]]; then
	eval "$BRM- $(($column - 1)) $(find $jobpath/in/ -type p | xargs) \
		${output:+| pv >$output}"
else
	# use sort -m if we don't have brm
	# sort -m creates tmp files if too many input files are specified
	# brm doesn't do this
	eval "sort -k$column,$column -m $jobpath/in/* ${output:+| pv >$output}"
fi

# Cleanup
rm -rf $jobpath
for host in $hosts; do
	ssh $host "rm -rf $nodepath"
done

# TODO: is there a safe way to kill subprocesses upon fail?
# this seems to work: /bin/kill -- -$$
